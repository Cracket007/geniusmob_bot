from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from langchain.output_parsers import ResponseSchema, StructuredOutputParser
from langchain_openai import ChatOpenAI
from langchain.chains import ConversationChain
from typing import Dict
from config import SYSTEM_INSTRUCTION

class ServiceCenter:
    def __init__(self):
        self.llm = ChatOpenAI()
        self.memories: Dict[int, ConversationBufferMemory] = {}
        
        # –ü–∞—Ä—Å–µ—Ä –¥–ª—è –∑–∞—è–≤–æ–∫ –Ω–∞ —Ä–µ–º–æ–Ω—Ç
        response_schemas = [
            ResponseSchema(name="phone_model", description="–ú–æ–¥–µ–ª—å —Ç–µ–ª–µ—Ñ–æ–Ω–∞"),
            ResponseSchema(name="problem", description="–ü—Ä–æ–±–ª–µ–º–∞"),
            ResponseSchema(name="client_contact", description="–ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"),
            ResponseSchema(name="need_repair", description="–ù—É–∂–µ–Ω –ª–∏ —Ä–µ–º–æ–Ω—Ç")
        ]
        self.repair_parser = StructuredOutputParser.from_response_schemas(response_schemas)
        
        # –®–∞–±–ª–æ–Ω –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–æ–∫
        self.repair_prompt = PromptTemplate(
            template="""–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–∏–∞–ª–æ–≥–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ:
            1. –ú–æ–¥–µ–ª—å —Ç–µ–ª–µ—Ñ–æ–Ω–∞
            2. –ü—Ä–æ–±–ª–µ–º—É
            3. –ö–æ–Ω—Ç–∞–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–ª–∏–µ–Ω—Ç–∞
            4. –ù—É–∂–µ–Ω –ª–∏ —Ä–µ–º–æ–Ω—Ç

            {format_instructions}
            
            –î–∏–∞–ª–æ–≥:
            {chat_history}
            """,
            input_variables=["chat_history"],
            partial_variables={"format_instructions": self.repair_parser.get_format_instructions()}
        )
    
    def get_memory(self, user_id: int) -> ConversationBufferMemory:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ø–∞–º—è—Ç—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        if user_id not in self.memories:
            self.memories[user_id] = ConversationBufferMemory(return_messages=True)
        return self.memories[user_id]
    
    def process_message(self, user_id: int, message: str) -> str:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        memory = self.get_memory(user_id)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è API
        messages = [
            {"role": "system", "content": SYSTEM_INSTRUCTION}
        ] + memory.chat_memory.messages[-5:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 —Å–æ–æ–±—â–µ–Ω–∏–π
        
        print("\n=== –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ OpenAI ===")
        print("üîµ System:", SYSTEM_INSTRUCTION[:100] + "...")
        for msg in memory.chat_memory.messages[-5:]:
            print(f"{'üü¢' if msg.type == 'human' else 'ü§ñ'} {msg.type.capitalize()}: {msg.content}")
        
        conversation = ConversationChain(
            llm=self.llm,
            memory=memory,
            verbose=True  # –í–∫–ª—é—á–∞–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
        )
        
        response = conversation.predict(input=message)
        print("\n=== –û—Ç–≤–µ—Ç OpenAI ===")
        print("ü§ñ Assistant:", response)
        
        return response
    
    def check_repair_needed(self, user_id: int) -> dict:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞—è–≤–∫–∏"""
        memory = self.get_memory(user_id)
        chat_history = memory.load_memory_variables({})["history"]
        
        print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Ä–µ–º–æ–Ω—Ç–∞ ===")
        print("üìù –ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π...")
        
        repair_chain = self.llm.generate(
            [self.repair_prompt.format_prompt(chat_history=chat_history).to_string()]
        )
        
        try:
            repair_info = self.repair_parser.parse(repair_chain.generations[0][0].text)
            print("‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:", repair_info)
            return repair_info
        except Exception as e:
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ:", str(e))
            return None 